{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73bf052e",
   "metadata": {},
   "source": [
    "# Basic eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "02c7101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from taxipred.backend.data_processing import TaxiData\n",
    "\n",
    "taxidata = TaxiData()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ad77ec11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 11 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Trip_Distance_km       950 non-null    float64\n",
      " 1   Time_of_Day            950 non-null    object \n",
      " 2   Day_of_Week            950 non-null    object \n",
      " 3   Passenger_Count        950 non-null    float64\n",
      " 4   Traffic_Conditions     950 non-null    object \n",
      " 5   Weather                950 non-null    object \n",
      " 6   Base_Fare              950 non-null    float64\n",
      " 7   Per_Km_Rate            950 non-null    float64\n",
      " 8   Per_Minute_Rate        950 non-null    float64\n",
      " 9   Trip_Duration_Minutes  950 non-null    float64\n",
      " 10  Trip_Price             951 non-null    float64\n",
      "dtypes: float64(7), object(4)\n",
      "memory usage: 86.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# use info to see the column names aswell as number of nullvalues aswell as typing\n",
    "taxidata.df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0bca2398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trip_Distance_km</th>\n",
       "      <th>Time_of_Day</th>\n",
       "      <th>Day_of_Week</th>\n",
       "      <th>Passenger_Count</th>\n",
       "      <th>Traffic_Conditions</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Base_Fare</th>\n",
       "      <th>Per_Km_Rate</th>\n",
       "      <th>Per_Minute_Rate</th>\n",
       "      <th>Trip_Duration_Minutes</th>\n",
       "      <th>Trip_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.35</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>Clear</td>\n",
       "      <td>3.56</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.32</td>\n",
       "      <td>53.82</td>\n",
       "      <td>36.2624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.59</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>1.0</td>\n",
       "      <td>High</td>\n",
       "      <td>Clear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.43</td>\n",
       "      <td>40.57</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.87</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>1.0</td>\n",
       "      <td>High</td>\n",
       "      <td>Clear</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.15</td>\n",
       "      <td>37.27</td>\n",
       "      <td>52.9032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.33</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.48</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.15</td>\n",
       "      <td>116.81</td>\n",
       "      <td>36.4698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>3.0</td>\n",
       "      <td>High</td>\n",
       "      <td>Clear</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.32</td>\n",
       "      <td>22.64</td>\n",
       "      <td>15.6180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.64</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Clear</td>\n",
       "      <td>2.55</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.48</td>\n",
       "      <td>89.33</td>\n",
       "      <td>60.2028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.85</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>4.0</td>\n",
       "      <td>High</td>\n",
       "      <td>Rain</td>\n",
       "      <td>3.51</td>\n",
       "      <td>1.66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.05</td>\n",
       "      <td>11.2645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>43.44</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clear</td>\n",
       "      <td>2.97</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101.1216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30.45</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>3.0</td>\n",
       "      <td>High</td>\n",
       "      <td>Clear</td>\n",
       "      <td>2.77</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0.34</td>\n",
       "      <td>110.33</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>35.70</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>Rain</td>\n",
       "      <td>3.39</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.5657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Trip_Distance_km Time_of_Day Day_of_Week  Passenger_Count  \\\n",
       "0             19.35     Morning     Weekday              3.0   \n",
       "1             47.59   Afternoon     Weekday              1.0   \n",
       "2             36.87     Evening     Weekend              1.0   \n",
       "3             30.33     Evening     Weekday              4.0   \n",
       "4               NaN     Evening     Weekday              3.0   \n",
       "5              8.64   Afternoon     Weekend              2.0   \n",
       "6              3.85   Afternoon     Weekday              4.0   \n",
       "7             43.44     Evening     Weekend              3.0   \n",
       "8             30.45     Morning     Weekday              3.0   \n",
       "9             35.70   Afternoon     Weekday              2.0   \n",
       "\n",
       "  Traffic_Conditions Weather  Base_Fare  Per_Km_Rate  Per_Minute_Rate  \\\n",
       "0                Low   Clear       3.56         0.80             0.32   \n",
       "1               High   Clear        NaN         0.62             0.43   \n",
       "2               High   Clear       2.70         1.21             0.15   \n",
       "3                Low     NaN       3.48         0.51             0.15   \n",
       "4               High   Clear       2.93         0.63             0.32   \n",
       "5             Medium   Clear       2.55         1.71             0.48   \n",
       "6               High    Rain       3.51         1.66              NaN   \n",
       "7                NaN   Clear       2.97         1.87             0.23   \n",
       "8               High   Clear       2.77         1.78             0.34   \n",
       "9                Low    Rain       3.39         1.52             0.47   \n",
       "\n",
       "   Trip_Duration_Minutes  Trip_Price  \n",
       "0                  53.82     36.2624  \n",
       "1                  40.57         NaN  \n",
       "2                  37.27     52.9032  \n",
       "3                 116.81     36.4698  \n",
       "4                  22.64     15.6180  \n",
       "5                  89.33     60.2028  \n",
       "6                   5.05     11.2645  \n",
       "7                    NaN    101.1216  \n",
       "8                 110.33         NaN  \n",
       "9                    NaN     75.5657  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the actual look of the dataset. to better understand the columns\n",
    "taxidata.df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ac32ea02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Trip_Distance_km  Passenger_Count  Base_Fare  \\\n",
      "Trip_Distance_km               1.000000        -0.048397   0.032218   \n",
      "Passenger_Count               -0.048397         1.000000   0.022932   \n",
      "Base_Fare                      0.032218         0.022932   1.000000   \n",
      "Per_Km_Rate                   -0.017041         0.030213   0.003092   \n",
      "Per_Minute_Rate               -0.025902         0.034068  -0.019150   \n",
      "Trip_Duration_Minutes         -0.022102         0.022845   0.012035   \n",
      "Trip_Price                     0.849123        -0.014223   0.035533   \n",
      "\n",
      "                       Per_Km_Rate  Per_Minute_Rate  Trip_Duration_Minutes  \\\n",
      "Trip_Distance_km         -0.017041        -0.025902              -0.022102   \n",
      "Passenger_Count           0.030213         0.034068               0.022845   \n",
      "Base_Fare                 0.003092        -0.019150               0.012035   \n",
      "Per_Km_Rate               1.000000         0.029241               0.027199   \n",
      "Per_Minute_Rate           0.029241         1.000000              -0.024230   \n",
      "Trip_Duration_Minutes     0.027199        -0.024230               1.000000   \n",
      "Trip_Price                0.275135         0.141226               0.221211   \n",
      "\n",
      "                       Trip_Price  \n",
      "Trip_Distance_km         0.849123  \n",
      "Passenger_Count         -0.014223  \n",
      "Base_Fare                0.035533  \n",
      "Per_Km_Rate              0.275135  \n",
      "Per_Minute_Rate          0.141226  \n",
      "Trip_Duration_Minutes    0.221211  \n",
      "Trip_Price               1.000000  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# figure out important correlations\n",
    "# suspecting abnormally close to 1 correlation in a couple of these columns\n",
    "matrix = taxidata.df.select_dtypes(include=np.number).corr()\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f862af9c",
   "metadata": {},
   "source": [
    "## My Feature Selection Plan and Justification\n",
    "\n",
    "### The Main Predictor\n",
    "After looking at the data, it's obvious that **`Trip_Distance_km`** is the biggest factor for the **`Trip_Price`**. My correlation check proved this with a strong positive value, so it's the main feature I'll be using.\n",
    "\n",
    "***\n",
    "### Dropping Columns to Avoid Data Leakage\n",
    "\n",
    "I'm dropping several columns to ensure my model is realistic and doesn't \"cheat\" by looking at parts of the answer.\n",
    "\n",
    "**Fare Component Columns (`Base_Fare`, Rates, etc.)**\n",
    "\n",
    "My initial thought was that **`Base_Fare`**, **`Per_Km_Rate`**, and **`Per_Minute_Rate`** are used to calculate the final price. The low correlation values were confusing, so I decided to manually verify this to be sure.\n",
    "\n",
    "First, I needed a complete row of data to work with, so I chose **Row 0** since it had no missing values. Based on the column names, I pieced together the most likely formula:\n",
    "\n",
    "`Total Price = Base_Fare + (Trip_Distance_km * Per_Km_Rate) + (Trip_Duration_Minutes * Per_Minute_Rate)`\n",
    "\n",
    "I then plugged in the numbers from Row 0 to test this theory:\n",
    "\n",
    "* **Base Fare:** `3.56`\n",
    "* **Distance Cost:** `19.35 km * 0.80` = `15.48`\n",
    "* **Duration Cost:** `53.82 min * 0.32` = `17.2224`\n",
    "\n",
    "When I summed these components, the result was **36.2624**, which was a perfect match for the actual **`Trip_Price`**. This test confirmed that the price is a direct result of these columns, proving the data leakage I suspected.\n",
    "\n",
    "**The Trip Duration Problem**\n",
    "\n",
    "I'm also dropping **`Trip_Duration_Minutes`**. This was a tricky one since duration and price are clearly connected. However, the column in this dataset is the *actual* time the trip took, which is something I'd only know *after* it's over. For my model to be realistic, it has to predict the price from stuff I'd know at the start.\n",
    "\n",
    "If I had start and stop locations, I would have used an API to get an *estimated* duration and used that as a feature. Since I don't have that, using the actual duration is just cheating.\n",
    "\n",
    "***\n",
    "### Final Approach\n",
    "\n",
    "Based on this, I'll move forward using **`Trip_Distance_km`** and my categorical features: **`Time_of_Day`** , **`Day_of_Week`**,**`Passenger_Count`**,`Traffic_Conditions` to build the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae40b0dd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ade646a9",
   "metadata": {},
   "source": [
    "### Repairing Key Columns Using the Fare Formula\n",
    "\n",
    "Now that the exact mathematical formula connecting the fare components has been identified, I can use it as a powerful tool for data repair.\n",
    "\n",
    "By algebraically rearranging this formula, it's possible to calculate and fill in missing values for my key columns—the target variable **`Trip_Price`** and the main feature **`Trip_Distance_km`**. This is a deterministic process that allows me to repair these values with 100% accuracy, salvaging valuable rows that would otherwise be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e72573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Before Repair ---\n",
      "Missing values in key columns:\n",
      "Trip_Price          1\n",
      "Trip_Distance_km    2\n",
      "dtype: int64\n",
      "-------------------------\n",
      "--- After Repair ---\n",
      "Missing values in key columns:\n",
      "Trip_Price          0\n",
      "Trip_Distance_km    0\n",
      "dtype: int64\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "COLUMNS = {\n",
    "    \"DISTANCE\": \"Trip_Distance_km\",\n",
    "    \"BASE_FARE\": \"Base_Fare\",\n",
    "    \"KM_RATE\": \"Per_Km_Rate\",\n",
    "    \"MIN_RATE\": \"Per_Minute_Rate\", \n",
    "    \"DURATION\": \"Trip_Duration_Minutes\",\n",
    "    \"PRICE\": \"Trip_Price\"\n",
    "}\n",
    "\n",
    "def _log_repair_status(df: pd.DataFrame, stage: str, repaired_cols: list):\n",
    "    \"\"\"Internal helper function to log the status of missing values.\"\"\"\n",
    "    print(f\"--- {stage} ---\")\n",
    "    print(\"Missing values in key columns:\")\n",
    "    print(df[repaired_cols].isnull().sum())\n",
    "    print(\"-\" * 25)\n",
    "\n",
    "def repair_taxi_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Repairs price and distance columns using a known fare calculation formula\n",
    "    and logs the changes.\n",
    "\n",
    "    This function modifies the DataFrame in place.\n",
    "    \"\"\"\n",
    "    # Log the initial state before any changes are made\n",
    "    _log_repair_status(df, 'Before Repair', [COLUMNS[\"PRICE\"], COLUMNS[\"DISTANCE\"]])\n",
    "\n",
    "    # --- Repair Missing Trip Price ---\n",
    "    price_components = [\n",
    "        COLUMNS[\"BASE_FARE\"], COLUMNS[\"DISTANCE\"], COLUMNS[\"KM_RATE\"],\n",
    "        COLUMNS[\"DURATION\"], COLUMNS[\"MIN_RATE\"]\n",
    "    ]\n",
    "    mask_repair_price = df[COLUMNS[\"PRICE\"]].isnull() & df[price_components].notnull().all(axis=1)\n",
    "\n",
    "    if mask_repair_price.any():\n",
    "        df.loc[mask_repair_price, COLUMNS[\"PRICE\"]] = (\n",
    "            df.loc[mask_repair_price, COLUMNS[\"BASE_FARE\"]] +\n",
    "            (df.loc[mask_repair_price, COLUMNS[\"DISTANCE\"]] * df.loc[mask_repair_price, COLUMNS[\"KM_RATE\"]]) +\n",
    "            (df.loc[mask_repair_price, COLUMNS[\"DURATION\"]] * df.loc[mask_repair_price, COLUMNS[\"MIN_RATE\"]])\n",
    "        )\n",
    "\n",
    "    # --- Repair Missing Trip Distance ---\n",
    "    distance_components = [\n",
    "        COLUMNS[\"BASE_FARE\"], COLUMNS[\"KM_RATE\"], COLUMNS[\"MIN_RATE\"],\n",
    "        COLUMNS[\"DURATION\"], COLUMNS[\"PRICE\"]\n",
    "    ]\n",
    "    mask_repair_distance = df[COLUMNS[\"DISTANCE\"]].isnull() & df[distance_components].notnull().all(axis=1)\n",
    "    mask_repair_distance &= (df[COLUMNS[\"KM_RATE\"]] != 0)\n",
    "\n",
    "    if mask_repair_distance.any():\n",
    "        df.loc[mask_repair_distance, COLUMNS[\"DISTANCE\"]] = (\n",
    "            (df.loc[mask_repair_distance, COLUMNS[\"PRICE\"]] -\n",
    "             df.loc[mask_repair_distance, COLUMNS[\"BASE_FARE\"]] -\n",
    "             (df.loc[mask_repair_distance, COLUMNS[\"DURATION\"]] * df.loc[mask_repair_distance, COLUMNS[\"MIN_RATE\"]])) /\n",
    "            df.loc[mask_repair_distance, COLUMNS[\"KM_RATE\"]]\n",
    "        )\n",
    "    \n",
    "    # Log the final state after all repairs are attempted\n",
    "    _log_repair_status(df, 'After Repair', [COLUMNS[\"PRICE\"], COLUMNS[\"DISTANCE\"]])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# --- HOW TO USE THE FUNCTION ---\n",
    "\n",
    "# 1. Load your data (replace with your actual data)\n",
    "data = {\n",
    "    COLUMNS[\"DISTANCE\"]: [19.35, 47.59, 36.87, np.nan, 8.64, np.nan],\n",
    "    COLUMNS[\"BASE_FARE\"]: [3.56, 2.95, 2.70, 3.48, 2.55, 3.10],\n",
    "    COLUMNS[\"KM_RATE\"]: [0.80, 0.62, 1.21, 0.51, 1.71, 0.90],\n",
    "    COLUMNS[\"MIN_RATE\"]: [0.32, 0.43, 0.15, 0.15, 0.48, 0.30],\n",
    "    COLUMNS[\"DURATION\"]: [53.82, 40.57, 37.27, 116.81, 89.33, 60.0],\n",
    "    COLUMNS[\"PRICE\"]: [36.2624, np.nan, 52.9032, 36.4698, 60.2028, 62.0]\n",
    "}\n",
    "taxidata_df = pd.DataFrame(data)\n",
    "\n",
    "# 2. Run the repair function. It will now print the before/after status automatically.\n",
    "repaired_df = repair_taxi_data(taxidata_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba11c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Before Repair ---\n",
      "Missing values in key columns:\n",
      "Trip_Price          49\n",
      "Trip_Distance_km    50\n",
      "dtype: int64\n",
      "-------------------------\n",
      "--- After Repair ---\n",
      "Missing values in key columns:\n",
      "Trip_Price          17\n",
      "Trip_Distance_km     6\n",
      "dtype: int64\n",
      "-------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trip_Distance_km</th>\n",
       "      <th>Time_of_Day</th>\n",
       "      <th>Day_of_Week</th>\n",
       "      <th>Passenger_Count</th>\n",
       "      <th>Traffic_Conditions</th>\n",
       "      <th>Weather</th>\n",
       "      <th>Base_Fare</th>\n",
       "      <th>Per_Km_Rate</th>\n",
       "      <th>Per_Minute_Rate</th>\n",
       "      <th>Trip_Duration_Minutes</th>\n",
       "      <th>Trip_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.35</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>Clear</td>\n",
       "      <td>3.56</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.32</td>\n",
       "      <td>53.82</td>\n",
       "      <td>36.2624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.59</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>1.0</td>\n",
       "      <td>High</td>\n",
       "      <td>Clear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.43</td>\n",
       "      <td>40.57</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.87</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>1.0</td>\n",
       "      <td>High</td>\n",
       "      <td>Clear</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1.21</td>\n",
       "      <td>0.15</td>\n",
       "      <td>37.27</td>\n",
       "      <td>52.9032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.33</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.48</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.15</td>\n",
       "      <td>116.81</td>\n",
       "      <td>36.4698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.64</td>\n",
       "      <td>Evening</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>3.0</td>\n",
       "      <td>High</td>\n",
       "      <td>Clear</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.32</td>\n",
       "      <td>22.64</td>\n",
       "      <td>15.6180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>5.49</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Clear</td>\n",
       "      <td>2.39</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.49</td>\n",
       "      <td>58.39</td>\n",
       "      <td>34.4049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>45.95</td>\n",
       "      <td>Night</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Clear</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.96</td>\n",
       "      <td>62.1295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>7.70</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>Rain</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.18</td>\n",
       "      <td>33.1236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>47.56</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>Clear</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.17</td>\n",
       "      <td>114.94</td>\n",
       "      <td>61.2090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>22.85</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Clear</td>\n",
       "      <td>4.34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.23</td>\n",
       "      <td>29.69</td>\n",
       "      <td>45.4437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Trip_Distance_km Time_of_Day Day_of_Week  Passenger_Count  \\\n",
       "0               19.35     Morning     Weekday              3.0   \n",
       "1               47.59   Afternoon     Weekday              1.0   \n",
       "2               36.87     Evening     Weekend              1.0   \n",
       "3               30.33     Evening     Weekday              4.0   \n",
       "4                8.64     Evening     Weekday              3.0   \n",
       "..                ...         ...         ...              ...   \n",
       "995              5.49   Afternoon     Weekend              4.0   \n",
       "996             45.95       Night     Weekday              4.0   \n",
       "997              7.70     Morning     Weekday              3.0   \n",
       "998             47.56     Morning     Weekday              1.0   \n",
       "999             22.85     Morning     Weekend              3.0   \n",
       "\n",
       "    Traffic_Conditions Weather  Base_Fare  Per_Km_Rate  Per_Minute_Rate  \\\n",
       "0                  Low   Clear       3.56         0.80             0.32   \n",
       "1                 High   Clear        NaN         0.62             0.43   \n",
       "2                 High   Clear       2.70         1.21             0.15   \n",
       "3                  Low     NaN       3.48         0.51             0.15   \n",
       "4                 High   Clear       2.93         0.63             0.32   \n",
       "..                 ...     ...        ...          ...              ...   \n",
       "995             Medium   Clear       2.39         0.62             0.49   \n",
       "996             Medium   Clear       3.12         0.61              NaN   \n",
       "997                Low    Rain       2.08         1.78              NaN   \n",
       "998                Low   Clear       2.67         0.82             0.17   \n",
       "999             Medium   Clear       4.34          NaN             0.23   \n",
       "\n",
       "     Trip_Duration_Minutes  Trip_Price  \n",
       "0                    53.82     36.2624  \n",
       "1                    40.57         NaN  \n",
       "2                    37.27     52.9032  \n",
       "3                   116.81     36.4698  \n",
       "4                    22.64     15.6180  \n",
       "..                     ...         ...  \n",
       "995                  58.39     34.4049  \n",
       "996                  61.96     62.1295  \n",
       "997                  54.18     33.1236  \n",
       "998                 114.94     61.2090  \n",
       "999                  29.69     45.4437  \n",
       "\n",
       "[1000 rows x 11 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "repaired_df = repair_taxi_data(taxidata.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d688a27",
   "metadata": {},
   "source": [
    "### identifying makeup of nulls \n",
    "ive concluded that there is a fair bit of null values in the dataset.\n",
    "i wanna identify how spread out it is. to see if any rows have an overwhelming number of null values or if its limited to 1 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1de85d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d0d82ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 917 entries, 0 to 999\n",
      "Data columns (total 11 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Trip_Distance_km       917 non-null    float64\n",
      " 1   Time_of_Day            876 non-null    object \n",
      " 2   Day_of_Week            887 non-null    object \n",
      " 3   Passenger_Count        886 non-null    float64\n",
      " 4   Traffic_Conditions     881 non-null    object \n",
      " 5   Weather                883 non-null    object \n",
      " 6   Base_Fare              886 non-null    float64\n",
      " 7   Per_Km_Rate            887 non-null    float64\n",
      " 8   Per_Minute_Rate        883 non-null    float64\n",
      " 9   Trip_Duration_Minutes  888 non-null    float64\n",
      " 10  Trip_Price             917 non-null    float64\n",
      "dtypes: float64(7), object(4)\n",
      "memory usage: 86.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      Clear\n",
       "2      Clear\n",
       "3        NaN\n",
       "4      Clear\n",
       "5      Clear\n",
       "       ...  \n",
       "995    Clear\n",
       "996    Clear\n",
       "997     Rain\n",
       "998    Clear\n",
       "999    Clear\n",
       "Name: Weather, Length: 917, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_max_1_null = taxidata.df[taxidata.df.isnull().sum(axis=1) <2]\n",
    "df_with_max_1_null.info()\n",
    "df_with_max_1_null[\"Weather\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c2b66164",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[77]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# 1. Train the model using the training data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# 2. Make predictions on the unseen test data\u001b[39;00m\n\u001b[32m     24\u001b[39m predictions = model.predict(Xtest)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\PythonProjects\\taxi-prediction-fullstack--andreas-johansson\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\PythonProjects\\taxi-prediction-fullstack--andreas-johansson\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:618\u001b[39m, in \u001b[36mLinearRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    614\u001b[39m n_jobs_ = \u001b[38;5;28mself\u001b[39m.n_jobs\n\u001b[32m    616\u001b[39m accept_sparse = \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.positive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mcsr\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcsc\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcoo\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m618\u001b[39m X, y = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    619\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    620\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    621\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    623\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    625\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    628\u001b[39m has_sw = sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\PythonProjects\\taxi-prediction-fullstack--andreas-johansson\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2971\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2969\u001b[39m         y = check_array(y, input_name=\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m, **check_y_params)\n\u001b[32m   2970\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2971\u001b[39m         X, y = \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2972\u001b[39m     out = X, y\n\u001b[32m   2974\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\PythonProjects\\taxi-prediction-fullstack--andreas-johansson\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1368\u001b[39m, in \u001b[36mcheck_X_y\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1362\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1363\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires y to be passed, but the target y is None\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1364\u001b[39m     )\n\u001b[32m   1366\u001b[39m ensure_all_finite = _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[32m-> \u001b[39m\u001b[32m1368\u001b[39m X = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1369\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1370\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1371\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1383\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1385\u001b[39m y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n\u001b[32m   1387\u001b[39m check_consistent_length(X, y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\PythonProjects\\taxi-prediction-fullstack--andreas-johansson\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1105\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1099\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1100\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray.ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1101\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m while dim <= 2 is required\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1102\u001b[39m     )\n\u001b[32m   1104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1114\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\PythonProjects\\taxi-prediction-fullstack--andreas-johansson\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:120\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\PythonProjects\\taxi-prediction-fullstack--andreas-johansson\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:169\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    155\u001b[39m     msg_err += (\n\u001b[32m    156\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    168\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "feature_columns = [\"Trip_Distance_km\", \"Passenger_Count\"]\n",
    "X = df_with_max_1_null[feature_columns]\n",
    "\n",
    "y = df_with_max_1_null[\"Trip_Price\"] # You need to define your target variable\n",
    "\n",
    "# Initialize the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Split data into training and testing sets for robust evaluation\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 1. Train the model using the training data\n",
    "model.fit(Xtrain, ytrain)\n",
    "\n",
    "# 2. Make predictions on the unseen test data\n",
    "predictions = model.predict(Xtest)\n",
    "\n",
    "# 3. Evaluate the model's performance\n",
    "mse = mean_squared_error(ytest, predictions)\n",
    "r2 = r2_score(ytest, predictions)\n",
    "\n",
    "print(f\"Model Performance on Test Data:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"R-squared (R²): {r2:.2f}\")\n",
    "\n",
    "# You can also inspect the learned parameters of the line\n",
    "print(f\"\\nModel Parameters:\")\n",
    "print(f\"Coefficient (slope): {model.coef_[0]:.2f}\")\n",
    "print(f\"Intercept: {model.intercept_:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taxipred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
